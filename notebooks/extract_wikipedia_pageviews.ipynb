{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ยง# Extract: Wikipedia pageviews\n",
    "\n",
    "Takes the airflow execution date and scan wikipedia data download for files for last 24 hours. All files not already retreieved will be downloaded and unpacked.\n",
    "\n",
    "Files will be put in a folder named: `output_dir/year/month/day/`\n",
    "\n",
    "Files are named `yyyymmdd_hhmm_type.csv`\n",
    "\n",
    "#### Parameters:\n",
    "\n",
    "`execution_date_str` = the airflow exeuction date\n",
    "\n",
    "`output_root` = path to directory where this pipeline will create the yearly folders with sublevels \n",
    "\n",
    "`overlap_hours` = how many hours back in time should we look for files, sometimes it takes a while for the data to be created in the source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# airflow execution date\n",
    "execution_hour_str = \"2025-03-10 10:00:00\"\n",
    "output_root = \"/tmp/airflow/airflow_output\"\n",
    "overlap_hours = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution_hour_str: 2025-03-10 10:00:00\n",
      "output_root: /tmp/airflow/airflow_output\n",
      "execution_hour: 2025-03-10 10:00:00\n",
      "file already downloaded: /tmp/airflow/airflow_output/2025/2025-03/10/pageviews-20250310-100000.gz\n",
      "file already downloaded: /tmp/airflow/airflow_output/2025/2025-03/10/pageviews-20250310-090000.gz\n",
      "downloading: https://dumps.wikimedia.org/other/pageviews/2025/2025-03/pageviews-20250310-080000.gz\n",
      "file_size: 65628660\n",
      "output_dir: /tmp/airflow/airflow_output/2025/2025-03/10\n",
      "downloaded_file_size: 65628660\n",
      "downloading: https://dumps.wikimedia.org/other/pageviews/2025/2025-03/pageviews-20250310-070000.gz\n",
      "file_size: 61959504\n",
      "output_dir: /tmp/airflow/airflow_output/2025/2025-03/10\n",
      "downloaded_file_size: 61959504\n",
      "downloading: https://dumps.wikimedia.org/other/pageviews/2025/2025-03/pageviews-20250310-060000.gz\n",
      "file_size: 58426852\n",
      "output_dir: /tmp/airflow/airflow_output/2025/2025-03/10\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import requests\n",
    "import urllib\n",
    "\n",
    "print(f\"execution_hour_str: {execution_hour_str}\")\n",
    "print(f\"output_root: {output_root}\")\n",
    "\n",
    "execution_hour = datetime.datetime.strptime(execution_hour_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print(f\"execution_hour: {execution_hour}\")\n",
    "\n",
    "\n",
    "for retrieve_hour in (execution_hour - datetime.timedelta(hours=i) for i in range(24)):\n",
    "    output_dir = f\"{output_root}/{retrieve_hour.year}/{retrieve_hour.year}-{retrieve_hour.month:0>2}/{retrieve_hour.day:0>2}\"\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    output_file = f\"{output_dir}/pageviews-{retrieve_hour.year}{retrieve_hour.month:0>2}{retrieve_hour.day:0>2}-{retrieve_hour.hour:0>2}0000.gz\"\n",
    "    if os.path.isfile(output_file):\n",
    "        print(f\"file already downloaded: {output_file}\")\n",
    "        continue\n",
    "\n",
    "    url = (\n",
    "        \"https://dumps.wikimedia.org/other/pageviews/\"\n",
    "        f\"{retrieve_hour.year}/{retrieve_hour.year}-{retrieve_hour.month:0>2}/pageviews-{retrieve_hour.year}{retrieve_hour.month:0>2}{retrieve_hour.day:0>2}-{retrieve_hour.hour:0>2}0000.gz\"\n",
    "    )\n",
    "\n",
    "    response = requests.head(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"no file find for: {retrieve_hour} at {url}\")\n",
    "        continue\n",
    "    file_size = response.headers.get(\"Content-Length\")\n",
    "\n",
    "    print(f\"downloading: {url}\")\n",
    "    print(f\"file_size: {file_size}\")\n",
    "    print(f\"output_dir: {output_dir}\")\n",
    "    urllib.request.urlretrieve(url, output_file)\n",
    "\n",
    "    downloaded_file_size = os.path.getsize(output_file)\n",
    "    print(f\"downloaded_file_size: {downloaded_file_size}\")\n",
    "    if file_size and downloaded_file_size != int(file_size):\n",
    "        print(\n",
    "            f\"Error: downloaded file size {downloaded_file_size} does not match expected size {file_size}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
